#################################################
# Data import script for La Haute Borne Project #
#################################################
"""
This is the import script for the example ENGIE La Haute Borne project. Below
is a description of data quality for each data frame and an overview of the
steps taken to correct the raw data for use in the PRUF OA code.

1. SCADA dataframe
- 10-minute SCADA data for each of the four turbines in the project
- Power, wind speed, wind direction, nacelle position, wind vane, temperature,
  blade pitch
- Corrects to UTC timezone when importing
- Removes some outliers and stuck sensor values

2. Meter data frame
- 10-minute performance data provided in energy units (kWh)
- Generated by adding artificial electrical loss and uncertaitny to SCADA data
- No need for timezone correction

3. Curtailment data frame
- 10-minute availability and curtailment data in kwh
- Generated by estimating availability and curtailment from SCADA data
- Below-normal production classified as curtailment if present at all turbines.
  Otherwise, classified as availability loss
- No need for timezone correction

4. Reanalysis products
- Import MERRA-2 and ERA5 1-hour reanalysis data
- Wind speed, wind direction, temperature, and density

"""
import os
from zipfile import ZipFile

import numpy as np
import pandas as pd

import openoa.utils.timeseries as ts
import openoa.utils.unit_conversion as un
import openoa.utils.met_data_processing as met
from openoa import logging, logged_method_call
from openoa import PlantData
from openoa.utils import filters

logger = logging.getLogger()

def extract_data(path="data/la_haute_borne"):
    """
    Extract zip file containing project engie data.
    """
    if not os.path.exists(path):
        with ZipFile(path + ".zip") as zipfile:
            zipfile.extractall(path)


def prepare(path="data/la_haute_borne", scada_df = None):
    """
    Do all loading and preparation of the data for this plant.
    """

    # Extract data if necessary
    extract_data(path)

    # Set time frequencies of data in minutes
    meter_freq = "10T"  # Daily meter data
    curtail_freq = "10T"  # Daily curtailment data
    scada_freq = "10T"  # 10-min

    # Load meta data
    lat_lon = (48.452, 5.588)
    plant_capacity = 8.2  # MW
    num_turbines = 4
    turbine_capacity = 2.05  # MW

    ###################
    # SCADA DATA #
    ###################
    logger.info("Loading SCADA data")
    if scada_df is None:
        scada_df = pd.read_csv(f"{path}/la-haute-borne-data-2014-2015.csv")
    logger.info("SCADA data loaded")

    logger.info("Timestamp QC and conversion to UTC")
    # Get 'time' field in datetime format. Local time zone information is
    # encoded, so convert to UTC

    scada_df["time"] = pd.to_datetime(
        scada_df["Date_time"], utc=True
    ).dt.tz_localize(None)

    # Remove duplicated timestamps and turbine id
    scada_df = scada_df.drop_duplicates(
        subset=["time", "Wind_turbine_name"], keep="first",
    )

    # Set time as index
    scada_df.set_index("time", inplace=True, drop=False)

    logger.info("Correcting for out of range of temperature variables")
    # Handle extrema values for temperature. All other variables appear to
    # be reasonable.
    scada_df = scada_df[
        (scada_df["Ot_avg"] >= -15.0) & (scada_df["Ot_avg"] <= 45.0)
    ]

    logger.info("Flagging unresponsive sensors")

    # Due to data discretization, there appear to be a lot of repeating
    # values. But these filters seem to catch the obvious unresponsive
    # sensors.
    for id in scada_df.Wind_turbine_name.unique():
        temp_flag = filters.unresponsive_flag(
            scada_df.loc[scada_df.Wind_turbine_name == id, "Va_avg"], 3
        )
        scada_df.loc[
            (scada_df.Wind_turbine_name == id) & (temp_flag),
            ["Ba_avg", "P_avg", "Ws_avg", "Va_avg", "Ot_avg", "Ya_avg", "Wa_avg"],
        ] = np.nan
        temp_flag = filters.unresponsive_flag(
            scada_df.loc[scada_df.Wind_turbine_name == id, "Ot_avg"], 20
        )
        scada_df.loc[
            (scada_df.Wind_turbine_name == id) & (temp_flag), "Ot_avg"
        ] = np.nan

    # Put power in watts
    scada_df["Power_W"] = scada_df["P_avg"] * 1000

    # Convert pitch to range -180 to 180.
    scada_df["Ba_avg"] = scada_df["Ba_avg"] % 360
    scada_df.loc[scada_df["Ba_avg"] > 180.0, "Ba_avg"] = (
        scada_df.loc[scada_df["Ba_avg"] > 180.0, "Ba_avg"] - 360.0
    )

    # Calculate energy
    scada_df["energy_kwh"] = (
        un.convert_power_to_energy(scada_df["Power_W"], scada_freq) / 1000
    )

    logger.info("Converting field names to IEC 61400-25 standard")
    # Map to -25 standards

    # Note: there is no vane direction variable defined in -25, so
    # making one up
    scada_map = {
        "time": "time",
        "Wind_turbine_name": "id",
        "Power_W": "wtur_W_avg",
        "Ws_avg": "wmet_wdspd_avg",
        "Wa_avg": "wmet_HorWdDir_avg",
        "Va_avg": "wmet_VaneDir_avg",
        "Ya_avg": "wyaw_YwAng_avg",
        "Ot_avg": "wmet_EnvTmp_avg",
        "Ba_avg": "wrot_BlPthAngVal1_avg",
    }

    scada_df.rename(scada_map, axis="columns", inplace=True)

    # Remove the fields we are not yet interested in
    scada_df.drop(["Date_time", "time", "P_avg"], axis=1, inplace=True)

    ##############
    # METER DATA #
    ##############
    meter_df = pd.read_csv(f"{path}/plant_data.csv")  # Load Meter data

    # Create datetime field
    meter_df["time"] = pd.to_datetime(meter_df.time_utc).dt.tz_localize(None)
    meter_df.set_index("time", inplace=True, drop=False)

    # Drop the fields we don't need
    meter_df.drop(
        ["time_utc", "availability_kwh", "curtailment_kwh"], axis=1, inplace=True
    )

    meter_df.rename(columns={"net_energy_kwh": "energy_kwh"}, inplace=True)

    #####################################
    # Availability and Curtailment Data #
    #####################################
    curtail_df = pd.read_csv(f"{path}/plant_data.csv")  # Load Availability and Curtail data

    # Create datetime field
    curtail_df["time"] = pd.to_datetime(curtail_df.time_utc).dt.tz_localize(None)
    curtail_df.set_index("time", inplace=True, drop=False)

    # Already have availability and curtailment in kwh, so not much to do.

    # Drop the fields we don't need
    curtail_df.drop(["time_utc", "net_energy_kwh"], axis=1, inplace=True)

    ###################
    # REANALYSIS DATA #
    ###################

    # merra2
    reanalysis_merra2_df = pd.read_csv(f"{path}/merra2_la_haute_borne.csv")

    # calculate wind direction from u, v
    reanalysis_merra2_df["winddirection_deg"] = met.compute_wind_direction(
        reanalysis_merra2_df["u_50"],
        reanalysis_merra2_df["v_50"],
    )

    reanalysis_merra2_df.rename(
        {
            "datetime": "time",
            "ws_50m": "windspeed_ms",
            "u_50": "u_ms",
            "v_50": "v_ms",
            "temp_2m": "temperature_K",
            "dens_50m": "rho_kgm-3",
        },
        axis="columns", inplace=True
    )
    reanalysis_merra2_df["time"] = pd.to_datetime(reanalysis_merra2_df["time"])
    reanalysis_merra2_df.set_index("time", inplace=True, drop=False)

    # Drop the fields we don't need
    reanalysis_merra2_df.drop(
        ["Unnamed: 0"], axis=1, inplace=True
    )

    # era5
    reanalysis_era5_df = pd.read_csv(f"{path}/era5_wind_la_haute_borne.csv")

    # calculate wind direction from u, v
    reanalysis_era5_df["winddirection_deg"] = met.compute_wind_direction(
        reanalysis_era5_df["u_100"],
        reanalysis_era5_df["v_100"],
    )

    reanalysis_era5_df.rename(
        {
            "datetime": "time",
            "ws_100m": "windspeed_ms",
            "u_100": "u_ms",
            "v_100": "v_ms",
            "t_2m": "temperature_K",
            "dens_100m": "rho_kgm-3",
        },
        axis="columns", inplace=True
    )
    reanalysis_era5_df["time"] = pd.to_datetime(reanalysis_era5_df["time"])
    reanalysis_era5_df.set_index("time", inplace=True, drop=False)

    # Drop the fields we don't need
    reanalysis_era5_df.drop(["Unnamed: 0"], axis=1, inplace=True)

    ##############
    # ASSET DATA #
    ##############
    asset_df = pd.read_csv(f"{path}/era5_wind_la_haute_borne.csv")

    asset_df.rename(
        {
            "Wind_turbine_name": "id",
            "Latitude": "latitude",
            "Longitude": "longitude",
            "Rated_power": "rated_power_kw",
            "Hub_height_m": "hub_height_m",
            "Rotor_diameter_m": "rotor_diameter_m",
        },
        axis="columns", inplace=True
    )

    # Assign type to turbine for all assets
    asset_df["type"] = "turbine"

    # Build and return PlantData
    engie_plantdata = PlantData(
        analysis_type="MonteCarloAEP",  # Choosing a random type that doesn't fail validation
        metadata="data/plant_meta.yml",
        scada=scada_df,
        meter=meter_df,
        curtail=curtail_df,
        asset=asset_df,
        reanalysis=dict(era5=reanalysis_era5_df, merra2=reanalysis_merra2_df),
    )

    return engie_plantdata
