{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the v3 `PlantData` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openoa import PlantData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "[datetime.datetime(2014, 1, 1, 1, 0, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2014, 1, 1, 1, 0, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2014, 1, 1, 1, 0, tzinfo=tzoffset(None, 3600)) ...\n datetime.datetime(2016, 1, 1, 0, 50, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2016, 1, 1, 0, 50, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2016, 1, 1, 0, 50, tzinfo=tzoffset(None, 3600))]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d14d6b877896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0myaml_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/plant_meta.yml\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m project = PlantData(\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0manalysis_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Choosing a random type that doesn't fail validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<attrs generated init openoa.plant.PlantData>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, metadata, analysis_type, scada, meter, tower, status, curtail, asset, reanalysis, preprocess)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0m__attr_validator_curtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__attr_curtail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurtail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0m__attr_validator_asset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__attr_asset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__attrs_post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/OpenOA/openoa/plant.py\u001b[0m in \u001b[0;36m__attrs_post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__attrs_post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreanalysis_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_index_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;31m# Check the errors againts the analysis requirements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/OpenOA/openoa/plant.py\u001b[0m in \u001b[0;36m_set_index_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mtime_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mid_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/openoa/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         dtarr = DatetimeArray._from_sequence_not_strict(\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/openoa/lib/python3.8/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_from_sequence_not_strict\u001b[0;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_infer_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         subarr, tz, inferred_freq = sequence_to_dt64ns(\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/openoa/lib/python3.8/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36msequence_to_dt64ns\u001b[0;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m   1971\u001b[0m             \u001b[0;31m# data comes back here as either i8 to denote UTC timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m             \u001b[0;31m#  or M8[ns] to denote wall times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m             data, inferred_tz = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m   1974\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myearfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m             )\n",
      "\u001b[0;32m/opt/miniconda3/envs/openoa/lib/python3.8/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[1;32m   2107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallow_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2110\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m         \u001b[0;31m# GH#23675 this TypeError should never be hit, whereas the TypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: [datetime.datetime(2014, 1, 1, 1, 0, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2014, 1, 1, 1, 0, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2014, 1, 1, 1, 0, tzinfo=tzoffset(None, 3600)) ...\n datetime.datetime(2016, 1, 1, 0, 50, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2016, 1, 1, 0, 50, tzinfo=tzoffset(None, 3600))\n datetime.datetime(2016, 1, 1, 0, 50, tzinfo=tzoffset(None, 3600))]"
     ]
    }
   ],
   "source": [
    "# project = Project_Engie('./data/la_haute_borne')\n",
    "# project.prepare()\n",
    "\n",
    "fpath = Path(\"data/la_haute_borne\")\n",
    "fn_scada = fpath / \"la-haute-borne-data-2014-2015.csv\"\n",
    "fn_meter = fpath / \"plant_data.csv\"\n",
    "fn_curtail = fpath / \"plant_data.csv\"\n",
    "fn_reanalysis_merra2 = fpath / \"merra2_la_haute_borne.csv\"\n",
    "fn_reanalysis_era5 = fpath / \"era5_wind_la_haute_borne.csv\"\n",
    "fn_asset = fpath / \"la-haute-borne_asset_table.csv\"\n",
    "\n",
    "yaml_meta = \"data/plant_meta.yml\"\n",
    "project = PlantData(\n",
    "    analysis_type=None,  # Choosing a random type that doesn't fail validation\n",
    "    metadata=yaml_meta,\n",
    "    scada=fn_scada,\n",
    "    meter=fn_meter,\n",
    "    curtail=fn_curtail,\n",
    "    asset=fn_asset,\n",
    "    reanalysis=dict(era5=fn_reanalysis_era5, merra2=fn_reanalysis_merra2),\n",
    ")\n",
    "\n",
    "# Create missing variables from the data set\n",
    "project.asset[\"type\"] = \"turbine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openoa import PlantData\n",
    "\n",
    "import project_ENGIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading SCADA data\n",
      "INFO:root:SCADA data loaded\n",
      "INFO:root:Timestamp QC and conversion to UTC\n",
      "INFO:root:Correcting for out of range of temperature variables\n",
      "INFO:root:Flagging unresponsive sensors\n",
      "INFO:root:Converting field names to IEC 61400-25 standard\n"
     ]
    }
   ],
   "source": [
    "scada_df, meter_df, curtail_df, asset_df, reanalysis_dict = project_ENGIE.prepare(return_value=\"dataframes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engie = PlantData(\n",
    "    analysis_type=None,\n",
    "    metadata=\"data/plant_meta.yml\",\n",
    "    scada=scada_df,\n",
    "    meter=meter_df,\n",
    "    curtail=curtail_df,\n",
    "    asset=asset_df,\n",
    "    reanalysis=reanalysis_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`scada` data is missing the following columns: ['status']\n`meter` data is missing the following columns: ['power']\n`tower` data is missing the following columns: ['time', 'id']\n`status` data is missing the following columns: ['time', 'id', 'status_id', 'status_code', 'status_text']\n`scada` data columns were of the wrong type: ['status']\n`meter` data columns were of the wrong type: ['power']\n`tower` data columns were of the wrong type: ['time', 'id']\n`status` data columns were of the wrong type: ['time', 'id', 'status_id', 'status_code', 'status_text']\n`scada` data is of the wrong frequency: None\n`reanalysis-era5` data is of the wrong frequency: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9476e55f001b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mengie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mengie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/OpenOA/openoa/plant.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompose_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_column_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `scada` data is missing the following columns: ['status']\n`meter` data is missing the following columns: ['power']\n`tower` data is missing the following columns: ['time', 'id']\n`status` data is missing the following columns: ['time', 'id', 'status_id', 'status_code', 'status_text']\n`scada` data columns were of the wrong type: ['status']\n`meter` data columns were of the wrong type: ['power']\n`tower` data columns were of the wrong type: ['time', 'id']\n`status` data columns were of the wrong type: ['time', 'id', 'status_id', 'status_code', 'status_text']\n`scada` data is of the wrong frequency: None\n`reanalysis-era5` data is of the wrong frequency: None"
     ]
    }
   ],
   "source": [
    "engie.analysis_type = \"all\"\n",
    "engie.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and create file mappings for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = Path(\"data/la_haute_borne\")\n",
    "fn_scada = fpath / \"la-haute-borne-data-2014-2015.csv\"\n",
    "fn_meter = fpath / \"plant_data.csv\"\n",
    "fn_curtail = fpath / \"plant_data.csv\"\n",
    "fn_reanalysis_merra2 = fpath / \"merra2_la_haute_borne.csv\"\n",
    "fn_reanalysis_era5 = fpath / \"era5_wind_la_haute_borne.csv\"\n",
    "fn_asset = fpath / \"la-haute-borne_asset_table.csv\"\n",
    "\n",
    "scada = pd.read_csv(fn_scada)\n",
    "meter = pd.read_csv(fn_meter)\n",
    "curtail = pd.read_csv(fn_curtail)\n",
    "reanalysis_era5 = pd.read_csv(fn_reanalysis_era5)\n",
    "reanalysis_merra2 = pd.read_csv(fn_reanalysis_merra2)\n",
    "asset = pd.read_csv(fn_asset)\n",
    "\n",
    "latitude = 48.4497\n",
    "longitude = 5.5896\n",
    "\n",
    "yaml_meta = \"data/plant_meta.yml\"\n",
    "json_meta = \"data/plant_meta.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    " - [x] read data from spark, csv, pandas\n",
    " - [x] read metadata from json, yaml, dict, and pre-loaded object\n",
    " - [x] automatically calculate wind direction from u/v windspeed\n",
    " - [x] call planetos api if API key is provided\n",
    "   - [x] validate this works\n",
    " - [x] support flags for if csv/planetos/data object/etc\n",
    " - datetime column frequency checks\n",
    "    - [ ] check against the provided metadata\n",
    "    - [ ] validate against the analysis requirements\n",
    "    - **note**: bring Lewis into this conversation on datetime & frequency validation, but is ok to use pandas for now\n",
    " - [x] expand metadata to contain plant-level identifiers (latitude, longitude)\n",
    " - check against the -25 namings and (likely) adopt that naming convention for the plant data\n",
    "   - [ ] update internal column naming convention to the -25 schema (Eric/Lewis)\n",
    " - [x] map the input column names, and provide a method to provide them back as the original inputs\n",
    " - [x] get the 0 notebook working, or at least as a means to understand what will be required for refactoring\n",
    " - [x] no failures for tower data as it's not used\n",
    " - [x] none flag for raising warning, not error, for missing/bad data\n",
    "   - `None` will run no validation\n",
    " - [ ] flag to not raise an error for known missing data\n",
    " - [x] metadata keyword argument for validate() to recreate `PlantMetaData`\n",
    "     - allows for more flexibility in use cases, especially in the exploratory phase, or for changing analysis types\n",
    " - [ ] review the v3 todo workbook to stay on track with the rest of v3 development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary of plant meta data \n",
    "\n",
    "**NOTE**: the datetime frequency checking is not in place, but the placeholder exists to implement it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_meta = dict(\n",
    "    latitude=latitude,\n",
    "    longitude=longitude,\n",
    "    scada=dict(\n",
    "        time=\"Date_time\",\n",
    "        id=\"Wind_turbine_name\",\n",
    "        power=\"P_avg\",\n",
    "        windspeed=\"Ws_avg\",\n",
    "#         wtur_wspd=\"Ws_avg\",  # TODO: adopt the -25 naming\n",
    "        wind_direction=\"Wa_avg\",\n",
    "#         status=\"?\",\n",
    "        pitch=\"Ba_avg\",\n",
    "        temperature=\"Ot_avg\",\n",
    "        frequency=\"10T\",\n",
    "    ),\n",
    "    meter=dict(\n",
    "        time=\"time_utc\",\n",
    "        energy=\"net_energy_kwh\",\n",
    "    ),\n",
    "    curtail=dict(\n",
    "        time=\"time_utc\",\n",
    "        curtailment=\"curtailment_kwh\",\n",
    "        availability=\"availability_kwh\",\n",
    "        net_energy=\"net_energy_kwh\",\n",
    "        frequency=\"10T\",\n",
    "    ),\n",
    "    reanalysis=dict(  # keys are informational/product-type, not pre-defined\n",
    "        era5=dict(\n",
    "            time=\"datetime\",\n",
    "            # windspeed=\"ws_100m\",  # Commented out to demonstrate variable creation from base windspeed data\n",
    "            windspeed_u=\"u_100\",\n",
    "            windspeed_v=\"v_100\",\n",
    "            temperature=\"t_2m\",\n",
    "            # density=\"dens_100m\",  # Commented out to demonstrate variable creation from base windspeed data\n",
    "            surface_pressure=\"surf_pres\",\n",
    "            frequency=\"H\",\n",
    "        ),\n",
    "        merra2=dict(\n",
    "            time=\"datetime\",\n",
    "            # windspeed=\"ws_50\",  # Commented out to demonstrate variable creation from base windspeed data\n",
    "            windspeed_u=\"u_50\",\n",
    "            windspeed_v=\"v_50\",\n",
    "            temperature=\"temp_10m\",\n",
    "            # density=\"dens_50\",  # Commented out to demonstrate variable creation from base windspeed data\n",
    "            surface_pressure=\"surface_pressure\",\n",
    "            frequency=\"H\",\n",
    "        )\n",
    "    ),\n",
    "    asset=dict(\n",
    "        id=\"id\",\n",
    "        latitude=\"Latitude\",\n",
    "        longitude=\"Longitude\",\n",
    "        rated_power=\"Rated_power\",\n",
    "        hub_height=\"Hub_height_m\",\n",
    "        rotor_diameter=\"Rotor_diameter_m\",\n",
    "        elevation=\"elevation_m\",\n",
    "#         type=\"?\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Recreate the YAML and JSON meta data objects as the dictionary above gets updated\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "with open(yaml_meta, \"w\") as f:\n",
    "    yaml.safe_dump(plant_meta, f, default_flow_style=False)\n",
    "    \n",
    "with open(json_meta, \"w\") as f:\n",
    "    json.dump(plant_meta, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate the loading from YAML, JSON, and dictionary produce the exact same meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_from_dict = PlantMetaData.from_dict(plant_meta)\n",
    "meta_from_json = PlantMetaData.from_json(json_meta)\n",
    "meta_from_yaml = PlantMetaData.from_yaml(yaml_meta)\n",
    "meta_from_dict == meta_from_json == meta_from_yaml, type(meta_from_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the PlantData capabilities\n",
    "\n",
    "### Load from `DataFrame`s and a metadata dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_from_data = PlantDataV3(\n",
    "    metadata=meta_from_dict,\n",
    "    scada=scada,\n",
    "    meter=meter,\n",
    "    curtail=curtail,\n",
    "    reanalysis={\"merra2\": reanalysis_merra2, \"era5\": reanalysis_era5},  # preferred, and enable API pulling\n",
    "    asset=asset,\n",
    "    analysis_type=\"MonteCarloAEP\",\n",
    ")\n",
    "type(plant_from_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show that \"windspeed\", \"wind_direction\", and \"density\" columns are all created from the core variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_from_data.reanalysis[\"era5\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_from_data.reanalysis[\"merra2\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show loading the data from file for both the meta data (JSON and YAML) and data (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_from_file1 = PlantDataV3(\n",
    "    metadata=yaml_meta,\n",
    "    scada=fn_scada,\n",
    "    meter=fn_meter,\n",
    "    curtail=fn_curtail,\n",
    "    reanalysis={\"merra2\": fn_reanalysis_merra2, \"era5\": fn_reanalysis_era5},  # preferred, and enable API pulling\n",
    "    asset=fn_asset,\n",
    "    analysis_type=\"MonteCarloAEP\"\n",
    ")\n",
    "type(plant_from_file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_from_file2 = PlantDataV3(\n",
    "    metadata=json_meta,\n",
    "    scada=fn_scada,\n",
    "    meter=fn_meter,\n",
    "    curtail=fn_curtail,\n",
    "    reanalysis={\"merra2\": fn_reanalysis_merra2, \"era5\": fn_reanalysis_era5},  # preferred, and enable API pulling\n",
    "    asset=fn_asset,\n",
    "    analysis_type=\"MonteCarloAEP\"\n",
    ")\n",
    "type(plant_from_file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When updating the `analysis_type` to \"all\", note all the column data errors that are saved until the end of the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_from_data = PlantDataV3(\n",
    "    metadata=meta_from_dict,\n",
    "    scada=scada,\n",
    "    meter=meter,\n",
    "    curtail=curtail,\n",
    "    reanalysis={\"merra2\": reanalysis_merra2, \"era5\": reanalysis_era5},  # preferred, and enable API pulling\n",
    "    asset=asset,\n",
    "    analysis_type=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate changing a parameter (`analysis_type`) and revalidating with `PlantDataV3.validate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = deepcopy(plant_from_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant.analysis_type = None\n",
    "plant.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant.analysis_type = \"all\"\n",
    "plant.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant.analysis_type = \"TurbineLongTermGrossEnergy\"\n",
    "plant.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant.analysis_type = \"ElectricalLosses\"\n",
    "plant.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct copy of the analysis requirements for easy referece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_REQUIREMENTS = {\n",
    "    \"MonteCarloAEP\": {\n",
    "        \"meter\": {\n",
    "            \"columns\": [\"energy\"],\n",
    "            \"freq\": (\"MS\", \"D\", \"H\", \"T\"),\n",
    "        },\n",
    "        \"curtail\": {\n",
    "            \"columns\": [\"availability\", \"curtailment\"],\n",
    "            \"freq\": (\"MS\", \"D\", \"H\", \"T\"),\n",
    "        },\n",
    "        \"reanalysis\": {\n",
    "            \"columns\": [\"windspeed\", \"rho\"],\n",
    "            \"conditional_columns\": {\n",
    "                \"reg_temperature\": [\"temperature\"],\n",
    "                \"reg_winddirection\": [\"windspeed_u\", \"windspeed_v\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"TurbineLongTermGrossEnergy\": {\n",
    "        \"scada\": {\n",
    "            \"columns\": [\"id\", \"windspeed\", \"power\"],  # TODO: wtur_W_avg vs energy_kwh ?\n",
    "            \"freq\": (\"D\", \"H\", \"T\"),\n",
    "        },\n",
    "        \"reanalysis\": {\n",
    "            \"columns\": [\"windspeed\", \"wind_direction\", \"rho\"],\n",
    "        },\n",
    "    },\n",
    "    \"ElectricalLosses\": {\n",
    "        \"scada\": {\n",
    "            \"columns\": [\"energy\"],\n",
    "            \"freq\": (\"D\", \"H\", \"T\"),\n",
    "        },\n",
    "        \"meter\": {\n",
    "            \"columns\": [\"energy\"],\n",
    "            \"freq\": (\"MS\", \"D\", \"H\", \"T\"),\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the updated column names and how to map them back to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scada.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant.scada.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant.update_column_names(to_original=True)\n",
    "plant.scada.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate the PlanetOS integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey_file = Path(\"./APIKEY\").resolve()\n",
    "plant_meta_planetos = deepcopy(plant_meta)\n",
    "plant_meta_planetos[\"reanalysis\"][\"era5\"] = dict(\n",
    "    time=\"datetime\",\n",
    "    windspeed=\"windspeed_ms\",\n",
    "    wind_direction=\"winddirection_deg\",\n",
    "    windspeed_u=\"u_ms\",\n",
    "    windspeed_v=\"v_ms\",\n",
    "    temperature=\"temperature_K\",\n",
    "    density=\"rho_kgm-3\",\n",
    "    surface_pressure=\"surf_pres_Pa\",\n",
    "    frequency=\"H\",\n",
    ")\n",
    "plant_meta_planetos[\"reanalysis\"][\"merra2\"] = dict(\n",
    "    time=\"datetime\",\n",
    "    windspeed=\"windspeed_ms\",\n",
    "    wind_direction=\"winddirection_deg\",\n",
    "    windspeed_u=\"u_ms\",\n",
    "    windspeed_v=\"v_ms\",\n",
    "    temperature=\"temperature_K\",\n",
    "    density=\"rho_kgm-3\",\n",
    "    surface_pressure=\"surf_pres_Pa\",\n",
    "    frequency=\"H\",\n",
    ")\n",
    "\n",
    "plant_from_data = PlantDataV3(\n",
    "    metadata=meta_from_dict,\n",
    "    scada=scada,\n",
    "    meter=meter,\n",
    "    curtail=curtail,\n",
    "    reanalysis={\n",
    "        \"merra2\": {\"apikey_file\": apikey_file, \"save_pathname\": \".\", \"save_filename\": \"merra2\"},\n",
    "        \"era5\": {\"apikey_file\": apikey_file, \"save_pathname\": \".\", \"save_filename\": \"era5\"},\n",
    "    },\n",
    "    asset=asset,\n",
    "    analysis_type=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
